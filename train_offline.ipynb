{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_utils.mydata import MyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'Electronics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_data/dataset_time_'+data_name+'.bin', 'rb') as f:\n",
    "    data_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dataset statistic\n",
    "'''\n",
    "data_set.productNum, data_set.userNum, data_set.wordNum, len(data_set.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DBML_offline import PSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义参数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "实验参数\n",
    "'''\n",
    "embedding_dim = 50\n",
    "out_size = 10\n",
    "batch_size = 256\n",
    "neg_sample_num = data_set.neg_sample_num\n",
    "dataLen = len(data_set.train_data)\n",
    "batch_num = int(dataLen/batch_size)\n",
    "full_len = batch_num*batch_size\n",
    "time_bin_num = len(data_set.time_data)\n",
    "total_epoch = 2\n",
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device  = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbml = PSM(data_set.userNum,\n",
    "           data_set.productNum,\n",
    "           data_set.wordNum,\n",
    "           embedding_dim,\n",
    "           data_set.max_query_len,\n",
    "           data_set.max_review_len,\n",
    "           batch_size,\n",
    "           data_set.time_num + 1,\n",
    "           neg_num=5,\n",
    "           sample_num=1,\n",
    "           transfer_hidden_dim=100,\n",
    "           sigma_parameter=1e-3,\n",
    "           kl_parameter=1e-3,\n",
    "           word_parameter=1e0,\n",
    "           device=device)\n",
    "dbml.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbml = torch.nn.DataParallel(dbml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbml.load_state_dict(torch.load('./out/Electronics_2019-07-22-13-05-52_success.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dbml.to(device)\n",
    "data_gen = DataLoader(data_set, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dbml.to(device)\n",
    "optimizer = torch.optim.Adam(dbml.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbml.kl_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbml.train()\n",
    "total_epoch = 500\n",
    "total_batch = len(data_gen)\n",
    "for e in range(total_epoch):\n",
    "    for i, data in enumerate(data_gen):\n",
    "        \n",
    "        user_mean, user_std, query, item_mean_pos, item_std_pos, items_mean_neg, items_std_neg,\\\n",
    "        user_sample, product_sample, product_sample_neg, loss, dis_pos, dis_neg, word_mean_pos,\\\n",
    "        word_std_pos, word_mean_neg, word_std_neg \\\n",
    "        = dbml(\n",
    "        data[0][0].to(device), data[0][1].to(device),\n",
    "        torch.stack(data[0][2]).t().to(device), data[0][3].to(device),\n",
    "        torch.stack(data[0][4]).t().to(device), data[0][5].to(device), data[0][6].to(device),\n",
    "        torch.stack(data[1][0]).t().to(device),\n",
    "        torch.stack(data[1][1]).t().to(device))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss[0].backward()\n",
    "        optimizer.step()\n",
    "        if (i % 20 == 0):\n",
    "            print('E: {}/{} | B: {}/{} | Loss: {} | POS: {} | NEG: {}'.format(e, total_epoch, i, total_batch,loss[0].item(), dis_pos.item(), dis_neg.item()))\n",
    "            print('Loss:{} | Main:{} | Word:{} | KL:{}'.format(loss[0].item(), loss[1].item(), loss[2].item(), loss[3].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dbml.state_dict(), 'out/{}_{}_{}.pkl'.format( data_name, tt.strftime(\"%Y-%m-%d-%H-%M-%S\", tt.localtime()),'ok'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k, method=0):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "def mean_reciprocal_rank(r):\n",
    "    return np.sum(r / np.arange(1, r.size + 1))\n",
    "def hit_rate(r):\n",
    "    if (np.sum(r) >= 0.9):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_laten(q_linear, query, query_len, max_query_len):\n",
    "    '''\n",
    "    input size: (batch, maxQueryLen)\n",
    "    对query处理使用函数\n",
    "    tanh(W*(mean(Q))+b)\n",
    "    '''\n",
    "    query_len = torch.tensor(query_len).view(1,-1).float()\n",
    "    # size: ((batch, maxQueryLen))) ---> (batch, len(query[i]), embedding)\n",
    "    # query len mask 使得padding的向量为0\n",
    "    len_mask = torch.tensor([ [1.]*int(i.item())+[0.]*(max_query_len-int(i.item())) for i in query_len]).unsqueeze(2)\n",
    "    query = query.mul(len_mask)\n",
    "    query = query.sum(dim=1).div(query_len)\n",
    "    query = q_linear(query).tanh()\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbml.eval()\n",
    "device=torch.device('cpu')\n",
    "dbml.to(device)\n",
    "all_p_m = torch.empty(data_set.time_num, data_set.productNum, embedding_dim)\n",
    "for ii in range(data_set.time_num):\n",
    "    for i in range(data_set.productNum):\n",
    "        p_mean = dbml.item_mean(torch.tensor([i], device=device)).squeeze(1)\n",
    "        time= dbml.time_embdding(torch.tensor([ii], device=device)+torch.tensor(1, device=device)).squeeze(1)\n",
    "        p_mean = dbml.time2mean(torch.cat([p_mean, time], 1)).squeeze()\n",
    "        all_p_m[ii][i] = p_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = data_set.test_data\n",
    "test_counter = 0\n",
    "all_hr = 0\n",
    "all_ndcg = 0\n",
    "all_mrr = 0\n",
    "for ii in trange(len(eval_dataset)):\n",
    "    td = eval_dataset[ii]\n",
    "    '''\n",
    "    应该定义一个训练过的user， 这里简单的先取训练过的时间段的用户\n",
    "    '''\n",
    "    if (td[6] >= 0):\n",
    "        user = dbml.user_mean(torch.tensor([td[0]], device=device)).squeeze(1)\n",
    "        time= dbml.time_embdding(torch.tensor([td[6]], device=device)+torch.tensor(1, device=device)).squeeze(1)\n",
    "        user = dbml.time2mean(torch.cat([user, time], 1)).squeeze()\n",
    "        \n",
    "        query_len = td[3]\n",
    "        query = torch.cat(tuple([dbml.wordEmbedding_mean(torch.tensor([i], device=device).squeeze(0)) for i in td[2]])).view(1,-1,embedding_dim)\n",
    "        query = get_query_laten(dbml.queryLinear, query, query_len, data_set.max_query_len)\n",
    "        user_query = user+query\n",
    "#         uq_i = torch.empty(datasets.productNum)\n",
    "        user_query.squeeze_(0)\n",
    "        uq_i = (user_query - all_p_m[td[6]]).norm(2, dim=1)*(-1.)\n",
    "#         for i in range(datasets.productNum):\n",
    "#             p_mean = product_time_latent[td[6]+1][i][0]\n",
    "#             uq_i[i] = -1*(user_query-p_mean).norm(2).item()\n",
    "        ranks_order = uq_i.topk(20)[1]\n",
    "        r = torch.eq(ranks_order, td[1]).numpy()\n",
    "        all_hr += hit_rate(r)\n",
    "        all_mrr += mean_reciprocal_rank(r)\n",
    "        all_ndcg += dcg_at_k(r, 20, 1)\n",
    "        test_counter += 1\n",
    "hr = all_hr / float(test_counter+1e-6)\n",
    "mrr = all_mrr / float(test_counter+1e-6)\n",
    "ndcg = all_ndcg / float(test_counter+1e-6)\n",
    "print(hr, mrr, ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
